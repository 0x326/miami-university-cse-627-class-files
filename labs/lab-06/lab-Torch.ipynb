{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "gray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Torch\n",
    "\n",
    "Follow the instructions **appropriate for your system**\n",
    "https://pytorch.org/get-started/locally/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On _your laptops_ which probably DO NOT have CUDA\n",
    "```bash\n",
    "conda install -y pytorch-cpu torchvision-cpu -c pytorch\n",
    "```\n",
    "\n",
    "**The next example is for a GPU system, do NOT do both(!)**\n",
    "\n",
    "On _my_ system (GTX1080 GPU, NVIDIA Cuda v9.0)\n",
    "```bash\n",
    "conda install -y pytorch torchvision -c pytorch\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restart the notbook** so that the python interpreter can process some of the changes made during installation of torchvision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = MNIST('./mndist', train=True,  download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, target = training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(im);\n",
    "title(int(target));\n",
    "xticks([0, im.size[1]-1]);\n",
    "yticks([0, im.size[0]-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??transforms.ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??transforms.Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = MNIST('./mndist', train=True,  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = training_data[0]\n",
    "#data\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "images, targets = train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(images, targets):\n",
    "    ncols = ceil(sqrt(len(images)))\n",
    "    nrows = ceil(len(images)/ncols)\n",
    "    for i in range(len(images)):\n",
    "        subplot(nrows, ncols, i+1)\n",
    "        imshow(images[i].numpy().squeeze())\n",
    "        xticks([]); yticks([]); \n",
    "        if targets is not None:\n",
    "            xlabel(str(targets[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = images\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0], -1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(784, 10)\n",
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = fc.parameters()\n",
    "W.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(W.detach().numpy())\n",
    "xlim(0,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fc(x)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = a.argmax(1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(images, targets, predictions=None):\n",
    "    ncols = ceil(sqrt(len(images)))\n",
    "    nrows = ceil(len(images)/ncols)\n",
    "    for i in range(len(images)):\n",
    "        subplot(nrows, ncols, i+1)\n",
    "        imshow(images[i].numpy().squeeze())\n",
    "        xticks([]); yticks([]); \n",
    "        if predictions is not None:\n",
    "            xlabel(\"P:{}, T:{}\".format( predictions[i].numpy(), targets[i].numpy()))\n",
    "        elif targets is not None:\n",
    "            xlabel(\"T:{}\".format(targets[i].numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(images, targets, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        a = self.fc(x)\n",
    "        return a  # Will learn to treat 'a' as the natural parameters of a multinomial distr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # Will discuss lr and momentum later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the next cell is running, open up a terminal and type `nvidia-smi` to make sure you are using 100% of your GPU. This is not so important on such a small dataset / model, but for larger problems the (linear) time sivings add up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)               # Predict\n",
    "        loss = criterion(outputs, labels)   # Grade / Evaluate\n",
    "        loss.backward()                     # Determine how each parameter effected the loss\n",
    "        optimizer.step()                    # Update parameters \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(images).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(images, targets, y)\n",
    "savefig('examples.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALERT: This was ALL on TRAINING data -- we NEED TEST!!!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MNIST('./mndist', train=False,  download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cm = np.zeros((10,10), dtype=np.int64)\n",
    "    for x, y in iter(test_loader):\n",
    "        p = net(x).argmax(1).numpy()\n",
    "        for pred, true in zip(p, y):\n",
    "            cm[int(pred), int(true)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(cm, index = arange(10), columns = arange(10))\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install $\\texttt{seaborn}$ to plot confusion matrices (and many other things) easily.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, fmt='d', annot=True);\n",
    "ylabel('pred')\n",
    "xlabel('true');\n",
    "savefig('cm.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.trace(cm)/ np.sum(cm)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_from_cm(cm, labels, beta=1):\n",
    "    df = pd.DataFrame(index=list(labels)+['avg/total'], columns=['precision', 'recall', 'fmeasure','support'])\n",
    "    for i, label in enumerate(labels):\n",
    "        tp = cm[i,i]\n",
    "        p = cm[i,:].sum()\n",
    "        support = cm[:,i].sum()\n",
    "        fp = p-tp\n",
    "        fn = support-tp\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        fmeasure = (1+beta**2)*precision*recall/((beta**2)*precision + recall)\n",
    "        df['precision'][label] = precision\n",
    "        df['recall'][label] = recall\n",
    "        df['fmeasure'][label] = fmeasure\n",
    "        df['support'][label] = support\n",
    "    df['precision']['avg/total'] = df['precision'][:'avg/total'].mean()\n",
    "    df['recall']['avg/total'] = df['recall'][:'avg/total'].mean()\n",
    "    df['fmeasure']['avg/total'] = df['fmeasure'][:'avg/total'].mean()\n",
    "    df['support']['avg/total'] = df['support'][:'avg/total'].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_from_cm(cm, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convention: Extention 'pth' seems to be from PyTorcH. Files are compressed with tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dict(epoch=epoch, \n",
    "                params=net.state_dict(),\n",
    "                optimizer=optimizer.state_dict()), \n",
    "           'mnist-linear.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('mnist-linear.pth.tar')\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resume later\n",
    "net.load_state_dict(state['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I typically write a class for doing the training. \n",
    "\n",
    "* I calculate test-loss every epoch\n",
    "* I produce a plot of the running train /test losses\n",
    "* I look for indications that there was a problem (NaN's, dead layers) after each epoch\n",
    "* I save the model to a file (checkpoint.pth.tar) every epoch\n",
    "    * If diskspace is not an issue, I save all of the checkpoints. This lets me go back and visualize how the net changed during learning\n",
    "* I save the best model to a file (best.pth.tar) if it changes at each epoch\n",
    "* I save the entire history to a log file\n",
    "* I use progressbars from https://pypi.org/project/tqdm/ for each epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training _curriculum_ will train multiple times, on increasingly complex versions of the problem. \n",
    "* Start with small images [8x8] and then increase the size\n",
    "* Start with one layer, then add more\n",
    "* Start with a pretrained model and freeze only the output, or input, layers initially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next:\n",
    "- Look at https://github.com/pytorch/tnt\n",
    "- Look at https://github.com/ncullen93/torchsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
